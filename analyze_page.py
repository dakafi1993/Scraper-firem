"""
Analyzuje HTML strukturu strÃ¡nky s firmami
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time

def setup_driver():
    options = Options()
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

print("ğŸ” ANALYZUJI STRUKTURU ALEO.COM")
print("=" * 60)

driver = setup_driver()

try:
    url = "https://aleo.com/pl/firmy/artykuly-dla-biur-i-wyposazenie-biurowe"
    print(f"\nğŸ“‚ URL: {url}")
    
    driver.get(url)
    print("\nâš ï¸  VyÅ™eÅ¡te Cloudflare checkbox...")
    time.sleep(15)  # ÄŒas na vyÅ™eÅ¡enÃ­ Cloudflare
    
    print("\nğŸ“„ Analyzuji HTML...")
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    
    # UloÅ¾it HTML pro inspekci
    with open('page_structure.html', 'w', encoding='utf-8') as f:
        f.write(soup.prettify())
    print("âœ… HTML uloÅ¾eno do: page_structure.html")
    
    # Hledat vÅ¡echny odkazy
    print("\nğŸ”— VÅ ECHNY ODKAZY (prvnÃ­ch 50):")
    print("-" * 60)
    links = soup.find_all('a', href=True)[:50]
    for i, link in enumerate(links, 1):
        href = link['href']
        text = link.get_text(strip=True)[:50]
        print(f"{i}. {href}")
        if text:
            print(f"   Text: {text}")
    
    # Hledat odkazy s /pl/firma/
    print(f"\nğŸ¯ ODKAZY s '/pl/firma/':")
    print("-" * 60)
    company_links = [a for a in soup.find_all('a', href=True) if '/pl/firma/' in a['href']]
    print(f"Nalezeno: {len(company_links)}")
    for link in company_links[:10]:
        print(f"  â€¢ {link['href']}")
        print(f"    Text: {link.get_text(strip=True)}")
    
    # Hledat rÅ¯znÃ© CSS tÅ™Ã­dy
    print(f"\nğŸ“‹ ELEMENTY s class obsahujÃ­cÃ­ 'company' nebo 'firma':")
    print("-" * 60)
    elements = soup.find_all(class_=lambda x: x and ('company' in x.lower() or 'firma' in x.lower()))
    print(f"Nalezeno: {len(elements)}")
    for elem in elements[:10]:
        print(f"  â€¢ Tag: {elem.name}, Class: {elem.get('class')}")
        print(f"    Text: {elem.get_text(strip=True)[:80]}")
    
    # Hledat seznamy
    print(f"\nğŸ“ UL/OL SEZNAMY:")
    print("-" * 60)
    lists = soup.find_all(['ul', 'ol'])
    for i, lst in enumerate(lists[:5], 1):
        items = lst.find_all('li')
        print(f"{i}. {lst.name} - {len(items)} poloÅ¾ek, class: {lst.get('class')}")
        if items:
            print(f"   PrvnÃ­ poloÅ¾ka: {items[0].get_text(strip=True)[:60]}")
    
    print("\nâœ… AnalÃ½za dokonÄena!")
    print("PodÃ­vejte se do page_structure.html pro detaily")
    
finally:
    driver.quit()
