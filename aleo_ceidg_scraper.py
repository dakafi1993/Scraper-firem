"""
Aleo.com scraper s CEIDG API pro polsk√© firmy
1. Z√≠sk√° n√°zvy firem z aleo.com
2. Vyhled√° je v CEIDG (ve≈ôejn√° datab√°ze polsk√Ωch firem)
3. Z√≠sk√° weby a kontakty
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time
import re
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import os
import argparse

# === KONFIGURACE ===
OUTPUT_DIR = "output"
MAX_CLOUDFLARE_WAIT = 120
EMAIL_PATTERN = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')

def create_output_dir():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

def setup_driver():
    chrome_options = Options()
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            })
        '''
    })
    
    return driver

def wait_for_cloudflare(driver):
    print("\n‚ö†Ô∏è  CLOUDFLARE DETEKOV√ÅNA!")
    print("="*60)
    print("MANU√ÅLN√ç KROK:")
    print("1. Kliknƒõte na checkbox 'Verify you are human'")
    print("2. Vy≈ôe≈°te p≈ô√≠padnou captcha")
    print(f"\nƒåek√°m max. {MAX_CLOUDFLARE_WAIT} sekund...")
    print("="*60)
    
    start_time = time.time()
    while time.time() - start_time < MAX_CLOUDFLARE_WAIT:
        if "cloudflare" not in driver.page_source.lower() and "challenge" not in driver.page_source.lower():
            print("‚úÖ Cloudflare vy≈ôe≈°ena!")
            return True
        time.sleep(1)
    
    print("‚ùå Timeout")
    return False

def extract_company_names_from_page(driver):
    """Extrahuje n√°zvy firem z aleo.com"""
    print("  üîç Hled√°m n√°zvy firem...")
    
    time.sleep(5)
    
    # Scrollov√°n√≠
    for i in range(3):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
    
    companies = []
    
    try:
        # Zkus√≠me naj√≠t elementy s n√°zvy p≈ô√≠mo
        try:
            elements = driver.find_elements(By.CLASS_NAME, "catalog-row-first-line__company-name")
            if elements:
                print(f"  ‚úÖ Nalezeno {len(elements)} n√°zv≈Ø firem")
                
                for elem in elements:
                    try:
                        name = elem.text.strip()
                        if name and len(name) > 2:
                            companies.append({
                                'name': name,
                                'profile_url': ''  # Nem√°me p≈ô√≠m√Ω link, ale n√°zev staƒç√≠ pro CEIDG
                            })
                    except:
                        continue
        except:
            pass
        
        # Pokud nenajdeme, zkus√≠me linky
        if not companies:
            elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/pl/firma/']")
            
            if elements:
                print(f"  ‚úÖ Nalezeno {len(elements)} odkaz≈Ø")
                
                seen = set()
                for elem in elements:
                    try:
                        href = elem.get_attribute('href')
                        text = elem.text.strip()
                        
                        if href and text and len(text) > 2:
                            if '/pl/firma/' in href and '/pl/firmy/' not in href:
                                if href not in seen:
                                    seen.add(href)
                                    companies.append({
                                        'name': text,
                                        'profile_url': href
                                    })
                    except:
                        continue
    except Exception as e:
        print(f"  ‚ö†Ô∏è  Chyba: {str(e)}")
    
    # Odstranƒõn√≠ duplik√°t≈Ø podle n√°zvu
    seen_names = set()
    unique_companies = []
    for comp in companies:
        if comp['name'] not in seen_names:
            seen_names.add(comp['name'])
            unique_companies.append(comp)
    
    return unique_companies

def search_krs(company_name):
    """
    Vyhled√° firmu v KRS API (pro s.r.o., S.A. apod.)
    """
    try:
        clean_name = company_name.split('SP√ì≈ÅKA')[0].strip()
        clean_name = clean_name.split(' SP.')[0].strip()
        clean_name = clean_name.split(' S.A.')[0].strip()
        
        print(f"    üîç KRS API: {clean_name}")
        
        # API MS Justice - ve≈ôejn√© KRS API
        api_url = f"https://api-krs.ms.gov.pl/api/krs/OdpisAktualny/{requests.utils.quote(clean_name)}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json'
        }
        
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            
            # Extrakce kontakt≈Ø z KRS
            website = ''
            email = ''
            
            # KRS m√° slo≈æitƒõj≈°√≠ strukturu - zkus√≠me naj√≠t z√°kladn√≠ info
            if isinstance(data, dict):
                # P≈ôepsat podle skuteƒçn√© struktury KRS API
                print(f"    ‚úÖ Firma nalezena v KRS")
                return {'website': website, 'email': email}
        
        return None
        
    except Exception as e:
        print(f"    ‚ö†Ô∏è  KRS chyba: {str(e)}")
        return None

def search_ceidg(company_name):
    """
    Vyhled√° firmu v CEIDG datab√°zi (ve≈ôejn√© API polsk√Ωch firem)
    """
    try:
        # Oƒçistit n√°zev firmy od "SP√ì≈ÅKA..." apod.
        clean_name = company_name.split('SP√ì≈ÅKA')[0].strip()
        clean_name = clean_name.split(' SP.')[0].strip()
        clean_name = clean_name.split(' S.A.')[0].strip()
        
        print(f"    üîç CEIDG: {clean_name}")
        
        # CEIDG API endpoint
        api_url = "https://dane.biznes.gov.pl/api/ceidg/v1/firmy"
        
        params = {
            'nazwa': clean_name,
            'format': 'json'
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(api_url, params=params, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            
            # CEIDG vrac√≠ pole firem
            if isinstance(data, dict) and 'firmy' in data:
                firmy = data['firmy']
                if firmy and len(firmy) > 0:
                    firma = firmy[0]  # Prvn√≠ v√Ωsledek
                    
                    # Extrakce dat
                    website = firma.get('adresStronyInternetowej', '').strip()
                    email = firma.get('adresEmail', '').strip()
                    telefon = firma.get('numerTelefonu', '').strip()
                    nip = firma.get('nip', '').strip()
                    
                    result = {
                        'website': website if website else '',
                        'email': email if email else '',
                        'telefon': telefon if telefon else '',
                        'nip': nip if nip else ''
                    }
                    
                    if website:
                        print(f"    üåê Web: {website}")
                    if email:
                        print(f"    ‚úÖ Email: {email}")
                    if telefon:
                        print(f"    üìû Tel: {telefon}")
                    
                    return result
        
        return None
        
    except Exception as e:
        print(f"    ‚ö†Ô∏è  CEIDG chyba: {str(e)}")
        return None

def find_email_on_website(url):
    """Hled√° email na webu firmy"""
    if not url:
        return None
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        pages = [url, f"{url}/kontakt", f"{url}/contact"]
        
        for page_url in pages:
            try:
                response = requests.get(page_url, headers=headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    text = soup.get_text()
                    
                    emails = EMAIL_PATTERN.findall(text)
                    valid_emails = [
                        email for email in emails
                        if not any(skip in email.lower() for skip in 
                                  ['example.', 'test@', 'noreply', 'wix.com'])
                    ]
                    
                    if valid_emails:
                        return valid_emails[0]
            except:
                continue
        
        return None
    except:
        return None

def scrape_category(driver, category_url, max_companies=10):
    """Scrapuje jednu kategorii"""
    companies = []
    
    print(f"\nüìÇ Kategorie: {category_url}")
    
    try:
        driver.get(category_url)
        
        if "cloudflare" in driver.page_source.lower() or "challenge" in driver.page_source.lower():
            if not wait_for_cloudflare(driver):
                return companies
        
        # Extrakce n√°zv≈Ø firem z aleo.com
        company_list = extract_company_names_from_page(driver)
        
        if not company_list:
            print("  ‚ùå ≈Ω√°dn√© firmy nenalezeny")
            return companies
        
        print(f"  ‚úÖ Nalezeno {len(company_list)} firem")
        
        # Omezen√≠
        company_list = company_list[:max_companies]
        
        # Zpracov√°n√≠ ka≈æd√© firmy
        for idx, company in enumerate(company_list, 1):
            company_name = company['name']
            profile_url = company['profile_url']
            
            print(f"\n  [{idx}/{len(company_list)}] {company_name}")
            
            # Vyhled√°n√≠ v CEIDG
            ceidg_data = search_ceidg(company_name)
            
            website = ''
            email = ''
            telefon = ''
            nip = ''
            
            if ceidg_data:
                website = ceidg_data.get('website', '')
                email = ceidg_data.get('email', '')
                telefon = ceidg_data.get('telefon', '')
                nip = ceidg_data.get('nip', '')
                
                # Pokud CEIDG nem√° email, zkus√≠me ho naj√≠t na webu
                if website and not email:
                    print(f"    üìß Hled√°m email na webu...")
                    found_email = find_email_on_website(website)
                    if found_email:
                        email = found_email
                        print(f"    ‚úÖ Email nalezen: {email}")
            else:
                print(f"    ‚ö†Ô∏è  Firma nenalezena v CEIDG")
            
            companies.append({
                'name': company_name,
                'website': website,
                'email': email,
                'telefon': telefon,
                'nip': nip,
                'aleo_profile': profile_url,
                'category': category_url
            })
            
            time.sleep(1)  # Rate limiting
        
        print(f"\n‚úÖ Zpracov√°no: {len(companies)} firem")
        
    except Exception as e:
        print(f"‚ùå Chyba: {str(e)}")
    
    return companies

def main(categories, max_companies_per_category):
    print("\n" + "="*60)
    print("üöÄ ALEO.COM + CEIDG SCRAPER")
    print("="*60)
    
    all_companies = []
    driver = setup_driver()
    
    try:
        print(f"\n‚úÖ Kategorie ({len(categories)}):")
        for cat in categories:
            print(f"  ‚Ä¢ {cat}")
        
        print(f"\n‚öôÔ∏è  Limit: {max_companies_per_category} firem/kategorii")
        print("üöÄ Spou≈°t√≠m Chrome...")
        
        for idx, category_url in enumerate(categories, 1):
            print(f"\n{'='*60}")
            print(f"KATEGORIE {idx}/{len(categories)}")
            print("="*60)
            
            companies = scrape_category(driver, category_url, max_companies_per_category)
            all_companies.extend(companies)
            
            if idx < len(categories):
                print(f"\n‚è∏Ô∏è  Pauza 3s...")
                time.sleep(3)
        
    finally:
        driver.quit()
    
    # Export
    if all_companies:
        create_output_dir()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        csv_file = os.path.join(OUTPUT_DIR, f"aleo_ceidg_{timestamp}.csv")
        xlsx_file = os.path.join(OUTPUT_DIR, f"aleo_ceidg_{timestamp}.xlsx")
        
        df = pd.DataFrame(all_companies)
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        df.to_excel(xlsx_file, index=False, engine='openpyxl')
        
        print("\n" + "="*60)
        print("‚úÖ HOTOVO!")
        print("="*60)
        print(f"Celkem firem: {len(all_companies)}")
        print(f"Firem s emailem: {sum(1 for c in all_companies if c['email'])}")
        print(f"Firem s webem: {sum(1 for c in all_companies if c['website'])}")
        print(f"\nüìÅ Soubory:")
        print(f"  ‚Ä¢ {csv_file}")
        print(f"  ‚Ä¢ {xlsx_file}")
    else:
        print("\n‚ùå ≈Ω√°dn√© firmy!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Aleo.com + CEIDG scraper')
    parser.add_argument('--categories', nargs='+', help='URL kategori√≠')
    parser.add_argument('--category-file', default='kategorie.txt', help='Soubor s kategoriemi')
    parser.add_argument('--max', type=int, default=10, help='Max firem/kategorii')
    
    args = parser.parse_args()
    
    categories = []
    if args.categories:
        categories = args.categories
    elif os.path.exists(args.category_file):
        with open(args.category_file, 'r', encoding='utf-8') as f:
            categories = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    if not categories:
        print("‚ùå ≈Ω√°dn√© kategorie!")
        exit(1)
    
    main(categories, args.max)
